{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f471014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from pathlib import Path\n",
    "\n",
    "converterText = TextFileToDocument()\n",
    "converterPDF = PyPDFToDocument()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e835875",
   "metadata": {},
   "source": [
    "# Meta Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'basic_concepts' in locals():\n",
    "    basic_concepts = \"\"\n",
    "\n",
    "if not 'process_text' in locals():\n",
    "    process_text = \"\"\n",
    "\n",
    "if not 'process_name' in locals():\n",
    "    process_name = \"\"\n",
    "\n",
    "if not 'large_language_model' in locals():\n",
    "    large_language_model = \"\"\n",
    "\n",
    "if not 'prompt_name' in locals():\n",
    "    prompt_name = \"\"\n",
    "\n",
    "if not 'loop_limit' in locals():\n",
    "    loop_limit = \"20\"\n",
    "\n",
    "if not 'llm_url' in locals():\n",
    "    llm_url = \"http://localhost:11434\"\n",
    "\n",
    "# print(\"process_name:\", process_name)\n",
    "# print(\"process description: \", process_text)\n",
    "# print(\"llm:\" , large_language_model)\n",
    "# print(\"prompt_name:\", prompt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220aa56",
   "metadata": {},
   "source": [
    "# DCR - in-context learning / RGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ddf05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not read .. Skipping it. Error: [Errno 21] Is a directory: '.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicDCR = converterText.run(sources=[Path(basic_concepts)])\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "document_store.write_documents(basicDCR['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96401de8",
   "metadata": {},
   "source": [
    "# Prompt for Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context\n",
    "prompt_Role = \"\"\"\n",
    "[Context]\n",
    "Imaging you are an expert in Business Process Management with extensive knowledge about declarative process modelling. Additionally, you have specific knowledge about the modelling technique \"DCR\" (Dynamic Condition Response), that you extend with information from the following documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "I am going to feed you a textual description of some sort of Business Process. It could be a process in a company or organization. \n",
    "\"\"\"\n",
    "\n",
    "#Task\n",
    "prompt_Role = prompt_Role + \"\"\"\n",
    "{{ task }}\n",
    "\"\"\"\n",
    "task = \"\"\"\n",
    "Your task is to find all roles or actors for a DCR graph in the process description I will provide you with.\n",
    "\"\"\"\n",
    "\n",
    "# Output / Format\n",
    "prompt_Role = prompt_Role + \"\"\"\n",
    "Return the roles in an array in JSON format, similar to: {\"roles\": [...,...,...]}. Do not forget the delimiter \",\" between the identified roles. Do not use any other delimiter. Do not add any other information to your answer. Do not include duplicate roles. Do not repeat the task description in your answer. Do neither describe nor explain your answer. \n",
    "\"\"\"\n",
    "\n",
    "# Process Description\n",
    "prompt_Role = prompt_Role + \"\"\"\n",
    "The process description in question is:\n",
    "{{ process }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd6d40",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c82907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Role = prompt_Role + \"\"\"\n",
    "\n",
    "Consider the following as a correct example: \n",
    "Example Description: \"The process starts when the storage facility used by Puori sends a product sample to Ellipse. Ellipse then notifies Puori of the new sample. Before testing can begin, Puori then request a test of a sample through Ellipse. Ellipse must then test the product, as well as have additional testing done through Eurofarms.\"\n",
    "Correctly identified roles: {\"roles\": [\"Storage Facility\", \"Ellipse\", \"Puori\"]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb73e6",
   "metadata": {},
   "source": [
    "## Combine Role Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e0b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f333ac08830>\n",
       "ðŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OllamaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder = PromptBuilder(template=prompt_Role)\n",
    "llm = OllamaGenerator(model=large_language_model, url=llm_url, timeout=1200)\n",
    "\n",
    "role_pipeline = Pipeline()\n",
    "role_pipeline.add_component(\"retriever\", retriever)\n",
    "role_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "role_pipeline.add_component(\"llm\", llm)\n",
    "role_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "role_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3e5fb",
   "metadata": {},
   "source": [
    "# Prompt for Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de90867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context\n",
    "prompt_Activity = \"\"\"\n",
    "Imaging you are an expert in Business Process Management with extensive knowledge about declarative process modelling. Additionally, you have specific knowledge about the modelling technique \"DCR\" (Dynamic Condition Response), that you extend with information from the following documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "I am going to feed you a textual description of some sort of Business Process. It could be a process in a company or organization. \n",
    "\"\"\"\n",
    "\n",
    "#Task\n",
    "prompt_Activity = prompt_Activity + \"\"\"\n",
    "Your task is to find all activities or events for a DCR graph in the process description I will provide you with and map them to the following roles: {{ roles }}.\n",
    "\"\"\"\n",
    "\n",
    "# Output / Format\n",
    "prompt_Activity = prompt_Activity + \"\"\"\n",
    "Return the activitites as keys in key-value-pairs in JSON format, with their associated role as value, which should look like this: { {\"activity\": ..., \"role\": ...}, ...}. Do not forget the delimiter \",\" between the identified activities. Do not use any other delimiter. Do not alter the text. Do not add any other information to your answer. Do not include duplicate activities. Do not repeat the task description in your answer. Do neither describe nor explain your answer. \n",
    "\"\"\"\n",
    "\n",
    "# Process Description\n",
    "prompt_Activity = prompt_Activity + \"\"\"\n",
    "The process description in question is:\n",
    "{{ process }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee8e97",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f584e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Activity = prompt_Activity + \"\"\"\n",
    "\n",
    "Consider the following as a correct example: \n",
    "Example Description: \"Two weeks before the renting period is done, management needs to contact the seller to announce that the renting period is almost complete and ask the seller if they want an extension. However, it is also possible for sellers to contact management which then would not require management to contact them. If they do not want to extend, they will move out. If they would like an extension, management needs to check their revenue.\"\n",
    "Correctly identified activities: [{\"activity\": \"contact the seller to announce that the renting period is almost complete\",\"role\": \"Management\"},{\"activity\": \"ask the seller if they want an extension\",\"role\": \"Management\"},{\"activity\": \"contact management\",\"role\": \"Seller\"},{\"activity\": \"do not want to extend\",\"role\": \"Seller\"},{\"activity\": \"move out\",\"role\": \"Seller\"},{\"activity\": \"like an extension\",\"role\": \"Seller\"},{\"activity\": \"check their revenue\",\"role\": \"Management\"}]\n",
    "\"\"\"\n",
    "# [{\"activity\": brings in a defective computer, \"role\": \"customer\"},...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a3432",
   "metadata": {},
   "source": [
    "## Combine Activity Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72ee36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f333ac1cf50>\n",
       "ðŸš… Components\n",
       "  - retriever_Activity: InMemoryBM25Retriever\n",
       "  - prompt_builder_Activity: PromptBuilder\n",
       "  - llm2: OllamaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever_Activity.documents -> prompt_builder_Activity.documents (List[Document])\n",
       "  - prompt_builder_Activity.prompt -> llm2.prompt (str)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_Activity = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder_Activity = PromptBuilder(template=prompt_Activity)\n",
    "llm2 = OllamaGenerator(model=large_language_model, url=llm_url, timeout=1200)\n",
    "\n",
    "activity_pipeline = Pipeline()\n",
    "activity_pipeline.add_component(\"retriever_Activity\", retriever_Activity)\n",
    "activity_pipeline.add_component(\"prompt_builder_Activity\", prompt_builder_Activity)\n",
    "activity_pipeline.add_component(\"llm2\", llm2)\n",
    "activity_pipeline.connect(\"retriever_Activity\", \"prompt_builder_Activity.documents\")\n",
    "activity_pipeline.connect(\"prompt_builder_Activity\", \"llm2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed35fba5",
   "metadata": {},
   "source": [
    "# Prompt for Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a11c86",
   "metadata": {},
   "source": [
    "## Prompt for Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context\n",
    "prompt_Condition = \"\"\"\n",
    "Imaging you are an expert in Business Process Management with extensive knowledge about declarative process modelling. Additionally, you have specific knowledge about the modelling technique \"DCR\" (Dynamic Condition Response), that you extend with information from the following documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "I am going to feed you a textual description of some sort of Business Process. It could be a process in a company or organization. \n",
    "\"\"\"\n",
    "\n",
    "#Task\n",
    "prompt_Condition = prompt_Condition + \"\"\"\n",
    "Your task is to find and define all Condition constraints between the activities for a DCR graph in the process description I will provide you with, based on the already identified activities: {{ activities }}.\n",
    "The relation between the associated source activity and target activity must fall under the definition of a Condition in DCR. \n",
    "\"\"\"\n",
    "\n",
    "# Output / Format\n",
    "prompt_Condition = prompt_Condition + \"\"\"\n",
    "Return the DCR constraints as keys in key-value-pairs in JSON format, which should look like this: { {\"constraint\": \"Condition\", \"source activity: ..., \"target activity\": ...}, ...}. The constraint should be one of the constraint types of DCR and the activities its associated source and target activity. Do not forget the delimiter \",\" between the identified constraints. Do not use any other delimiter. Do not alter the text. Do not add any other information to your answer. Do not include duplicate constraints. Do not include the roles of the activities in the output. Do not repeat the task description in your answer. Do neither describe nor explain your answer. \n",
    "Remember that not all constraints between activities might be of type Condition, so you can also return an empty list.\n",
    "\"\"\"\n",
    "\n",
    "# Process Description\n",
    "prompt_Condition = prompt_Condition + \"\"\"\n",
    "The process description in question is:\n",
    "{{ process }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Condition = prompt_Condition + \"\"\"\n",
    "\n",
    "Consider the following correct example:\n",
    "\n",
    "Example for Condition: \"Once they have completed everything, they can get the bike from the shop and the contract will be started.\"\n",
    "Correctly identified Condition constraint: [{\"constraint\": \"Condition\", \"source activity\": \"have completed everything\", \"target activity\": \"get the bike from the shop\"},{\"constraint\": \"Condition\", \"source activity\": \"have completed everything\", \"target activity\": \"the contract will be started\"}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526b271",
   "metadata": {},
   "source": [
    "### Combine Condition Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fd70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fcd33b4b410>\n",
       "ðŸš… Components\n",
       "  - prompt_builder_Rules: PromptBuilder\n",
       "  - llm3: OllamaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder_Rules.prompt -> llm3.prompt (str)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_condition = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder_Condition = PromptBuilder(template=prompt_Condition)\n",
    "llm_cond = OllamaGenerator(model=model, url=llm_url, timeout=1200)\n",
    "\n",
    "condition_pipeline = Pipeline()\n",
    "condition_pipeline.add_component(\"retriever_condition\", retriever_condition)\n",
    "condition_pipeline.add_component(\"prompt_builder_Condition\", prompt_builder_Condition)\n",
    "condition_pipeline.add_component(\"llm_cond\", llm_cond)\n",
    "condition_pipeline.connect(\"retriever_condition\", \"prompt_builder_Condition.documents\")\n",
    "condition_pipeline.connect(\"prompt_builder_Condition\", \"llm_cond\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7bcaa1",
   "metadata": {},
   "source": [
    "## Prompt for Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context\n",
    "prompt_Response = \"\"\"\n",
    "Imaging you are an expert in Business Process Management with extensive knowledge about declarative process modelling. Additionally, you have specific knowledge about the modelling technique \"DCR\" (Dynamic Condition Response), that you extend with information from the following documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "I am going to feed you a textual description of some sort of Business Process. It could be a process in a company or organization. \n",
    "\"\"\"\n",
    "\n",
    "#Task\n",
    "prompt_Response = prompt_Response + \"\"\"\n",
    "Your task is to find and define all Response constraints between the activities for a DCR graph in the process description I will provide you with, based on the already identified activities: {{ activities }}.\n",
    "The relation between the associated source activity and target activity must fall under the definition of a Response in DCR. \n",
    "\"\"\"\n",
    "\n",
    "# Output / Format\n",
    "prompt_Response = prompt_Response + \"\"\"\n",
    "Return the DCR constraints as keys in key-value-pairs in JSON format, which should look like this: { {\"constraint\": \"Response\", \"source activity: ..., \"target activity\": ...}, ...}. The constraint should be one of the constraint types of DCR and the activities its associated source and target activity. Do not forget the delimiter \",\" between the identified constraints. Do not use any other delimiter. Do not alter the text. Do not add any other information to your answer. Do not include duplicate constraints. Do not include the roles of the activities in the output. Do not repeat the task description in your answer. Do neither describe nor explain your answer. \n",
    "Remember that not all constraints between activities might be of type Response, so you can also return an empty list.\n",
    "\"\"\"\n",
    "\n",
    "# Process Description\n",
    "prompt_Response = prompt_Response + \"\"\"\n",
    "The process description in question is:\n",
    "{{ process }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Response = prompt_Response + \"\"\"\n",
    "\n",
    "Consider the following correct example:\n",
    "\n",
    "Example for Response: \"If they do not want to extend, they will move out.\"\n",
    "Correctly identified Response constraint: {\"constraint\": \"Response\", \"source activity\": \"do not want to extend\", \"target activity\": \"move out\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b2bea",
   "metadata": {},
   "source": [
    "### Combine Response Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625bac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fcd33b4b410>\n",
       "ðŸš… Components\n",
       "  - prompt_builder_Rules: PromptBuilder\n",
       "  - llm3: OllamaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder_Rules.prompt -> llm3.prompt (str)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_response = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder_response = PromptBuilder(template=prompt_Response)\n",
    "llm_resp = OllamaGenerator(model=model, url=llm_url, timeout=1200)\n",
    "\n",
    "response_pipeline = Pipeline()\n",
    "response_pipeline.add_component(\"retriever_response\", retriever_response)\n",
    "response_pipeline.add_component(\"prompt_builder_response\", prompt_builder_response)\n",
    "response_pipeline.add_component(\"llm_resp\", llm_resp)\n",
    "response_pipeline.connect(\"retriever_response\", \"prompt_builder_response.documents\")\n",
    "response_pipeline.connect(\"prompt_builder_response\", \"llm_resp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab0155",
   "metadata": {},
   "source": [
    "## Prompt for Include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context\n",
    "prompt_Include = \"\"\"\n",
    "Imaging you are an expert in Business Process Management with extensive knowledge about declarative process modelling. Additionally, you have specific knowledge about the modelling technique \"DCR\" (Dynamic Condition Response), that you extend with information from the following documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "I am going to feed you a textual description of some sort of Business Process. It could be a process in a company or organization. \n",
    "\"\"\"\n",
    "\n",
    "#Task\n",
    "prompt_Include = prompt_Include + \"\"\"\n",
    "Your task is to find and define all Include constraints between the activities for a DCR graph in the process description I will provide you with, based on the already identified activities: {{ activities }}.\n",
    "The relation between the associated source activity and target activity must fall under the definition of a Include in DCR. \n",
    "\"\"\"\n",
    "\n",
    "# Output / Format\n",
    "prompt_Include = prompt_Include + \"\"\"\n",
    "Return the DCR constraints as keys in key-value-pairs in JSON format, which should look like this: { {\"constraint\": \"Include\", \"source activity: ..., \"target activity\": ...}, ...}. The constraint should be one of the constraint types of DCR and the activities its associated source and target activity. Do not forget the delimiter \",\" between the identified constraints. Do not use any other delimiter. Do not alter the text. Do not add any other information to your answer. Do not include duplicate constraints. Do not include the roles of the activities in the output. Do not repeat the task description in your answer. Do neither describe nor explain your answer. \n",
    "Remember that not all constraints between activities might be of type Include, so you can also return an empty list.\n",
    "\"\"\"\n",
    "\n",
    "# Process Description\n",
    "prompt_Include = prompt_Include + \"\"\"\n",
    "The process description in question is:\n",
    "{{ process }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Include = prompt_Include + \"\"\"\n",
    "\n",
    "Consider the following correct example:\n",
    "\n",
    "Example for Include: \"A customer must browse for products prior to adding a product to the basket, but they can access the basket upon entering the webshop without any prior conditions. In order to proceed to check-out at least one product must be in the basket.\"\n",
    "Correctly identified Include constraint: {\"constraint\": \"Include\", \"source activity\": \"adding a product to the basket\", \"target activity\": \"proceed to check-out\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39478757",
   "metadata": {},
   "source": [
    "### Combine Include Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62983050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fcd33b4b410>\n",
       "ðŸš… Components\n",
       "  - prompt_builder_Rules: PromptBuilder\n",
       "  - llm3: OllamaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder_Rules.prompt -> llm3.prompt (str)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_include = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder_include = PromptBuilder(template=prompt_Include)\n",
    "llm_include = OllamaGenerator(model=model, url=llm_url, timeout=1200)\n",
    "\n",
    "include_pipeline = Pipeline()\n",
    "include_pipeline.add_component(\"retriever_include\", retriever_include)\n",
    "include_pipeline.add_component(\"prompt_builder_include\", prompt_builder_include)\n",
    "include_pipeline.add_component(\"llm_include\", llm_include)\n",
    "include_pipeline.connect(\"retriever_include\", \"prompt_builder_include.documents\")\n",
    "include_pipeline.connect(\"prompt_builder_include\", \"llm_include\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65e602",
   "metadata": {},
   "source": [
    "## Prompt for Exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context\n",
    "prompt_Exclude = \"\"\"\n",
    "Imaging you are an expert in Business Process Management with extensive knowledge about declarative process modelling. Additionally, you have specific knowledge about the modelling technique \"DCR\" (Dynamic Condition Response), that you extend with information from the following documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "I am going to feed you a textual description of some sort of Business Process. It could be a process in a company or organization. \n",
    "\"\"\"\n",
    "\n",
    "#Task\n",
    "prompt_Exclude = prompt_Exclude + \"\"\"\n",
    "Your task is to find and define all Exclude constraints between the activities for a DCR graph in the process description I will provide you with, based on the already identified activities: {{ activities }}.\n",
    "The relation between the associated source activity and target activity must fall under the definition of a Exclude in DCR.\n",
    "\"\"\"\n",
    "\n",
    "# Output / Format\n",
    "prompt_Exclude = prompt_Exclude + \"\"\"\n",
    "Return the DCR constraints as keys in key-value-pairs in JSON format, which should look like this: { {\"constraint\": \"Exclude\", \"source activity: ..., \"target activity\": ...}, ...}. The constraint should be one of the constraint types of DCR and the activities its associated source and target activity. Do not forget the delimiter \",\" between the identified constraints. Do not use any other delimiter. Do not alter the text. Do not add any other information to your answer. Do not include duplicate constraints. Do not include the roles of the activities in the output. Do not repeat the task description in your answer. Do neither describe nor explain your answer. \n",
    "Remember that not all constraints between activities might be of type Exclude, so you can also return an empty list.\n",
    "\"\"\"\n",
    "\n",
    "# Process Description\n",
    "prompt_Exclude = prompt_Exclude + \"\"\"\n",
    "The process description in question is:\n",
    "{{ process }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Exclude = prompt_Exclude + \"\"\"\n",
    "\n",
    "Consider the following correct example:\n",
    "\n",
    "Example for Exclude: \"Two weeks before the renting period is done, management needs to contact the seller to announce that the renting period is almost complete and ask the seller if they want an extension. However, it is also possible for sellers to contact management which then would not require management to contact them.\"\n",
    "Correctly identified Exclude constraint: {\"constraint\": \"Exclude\", \"source activity\": \"contact management\", \"target activity\": \"contact the seller to announce that the renting period is almost complete\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2306db53",
   "metadata": {},
   "source": [
    "### Combine Exclude Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c006d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fcd33b4b410>\n",
       "ðŸš… Components\n",
       "  - prompt_builder_Rules: PromptBuilder\n",
       "  - llm3: OllamaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder_Rules.prompt -> llm3.prompt (str)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_exclude = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder_exclude = PromptBuilder(template=prompt_Exclude)\n",
    "llm_exclude = OllamaGenerator(model=model, url=llm_url, timeout=1200)\n",
    "\n",
    "exclude_pipeline = Pipeline()\n",
    "exclude_pipeline.add_component(\"retriever_exclude\", retriever_exclude)\n",
    "exclude_pipeline.add_component(\"prompt_builder_exclude\", prompt_builder_exclude)\n",
    "exclude_pipeline.add_component(\"llm_exclude\", llm_exclude)\n",
    "exclude_pipeline.connect(\"retriever_exclude\", \"prompt_builder_exclude.documents\")\n",
    "exclude_pipeline.connect(\"prompt_builder_exclude\", \"llm_exclude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c14e65",
   "metadata": {},
   "source": [
    "## Prompt for Milestone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fcc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Context\n",
    "prompt_Milestone = \"\"\"\n",
    "Imaging you are an expert in Business Process Management with extensive knowledge about declarative process modelling. Additionally, you have specific knowledge about the modelling technique \"DCR\" (Dynamic Condition Response), that you extend with information from the following documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "I am going to feed you a textual description of some sort of Business Process. It could be a process in a company or organization. \n",
    "\"\"\"\n",
    "\n",
    "#Task\n",
    "prompt_Milestone = prompt_Milestone + \"\"\"\n",
    "Your task is to find and define all Milestone constraints between the activities for a DCR graph in the process description I will provide you with, based on the already identified activities: {{ activities }}.\n",
    "The relation between the associated source activity and target activity must fall under the definition of a Milestone in DCR.\n",
    "\"\"\"\n",
    "\n",
    "# Output / Format\n",
    "prompt_Milestone = prompt_Milestone + \"\"\"\n",
    "Return the DCR constraints as keys in key-value-pairs in JSON format, which should look like this: { {\"constraint\": \"Milestone\", \"source activity: ..., \"target activity\": ...}, ...}. The constraint should be one of the constraint types of DCR and the activities its associated source and target activity. Do not forget the delimiter \",\" between the identified constraints. Do not use any other delimiter. Do not alter the text. Do not add any other information to your answer. Do not include duplicate constraints. Do not include the roles of the activities in the output. Do not repeat the task description in your answer. Do neither describe nor explain your answer.\n",
    "Remember that not all constraints between activities might be of type Milestone, so you can also return an empty list.\n",
    "\"\"\"\n",
    "\n",
    "# Process Description\n",
    "prompt_Milestone = prompt_Milestone + \"\"\"\n",
    "The process description in question is:\n",
    "{{ process }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885503ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Milestone = prompt_Milestone + \"\"\"\n",
    "\n",
    "Consider the following correct example:\n",
    "\n",
    "Example for Milestone: \"After the design is approved by the product owner, Marketing may send the design to test groups for feedback. After the design is approved, if the design is not sent to test groups, Marketing must send the design to P&R.\"\n",
    "Correctly identified Milestone constraint: {\"constraint\": \"Milestone\", \"source activity\": \"approve the design\", \"target activity\": \"send the design to P&R\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f07ded",
   "metadata": {},
   "source": [
    "### Combine Milestone Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6895e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fcd33b4b410>\n",
       "ðŸš… Components\n",
       "  - prompt_builder_Rules: PromptBuilder\n",
       "  - llm3: OllamaGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder_Rules.prompt -> llm3.prompt (str)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_milestone = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder_milestone = PromptBuilder(template=prompt_Milestone)\n",
    "llm_mile = OllamaGenerator(model=model, url=llm_url, timeout=1200)\n",
    "\n",
    "milestone_pipeline = Pipeline()\n",
    "milestone_pipeline.add_component(\"retriever_milestone\", retriever_milestone)\n",
    "milestone_pipeline.add_component(\"prompt_builder_milestone\", prompt_builder_milestone)\n",
    "milestone_pipeline.add_component(\"llm_mile\", llm_mile)\n",
    "milestone_pipeline.connect(\"retriever_milestone\", \"prompt_builder_milestone.documents\")\n",
    "milestone_pipeline.connect(\"prompt_builder_milestone\", \"llm_mile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c818aa",
   "metadata": {},
   "source": [
    "# Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7468d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET \n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9e402",
   "metadata": {},
   "source": [
    "## Run Prompt Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5311ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPromptPipeline(): \n",
    "    start_time_role = datetime.now()\n",
    "    response_Roles = role_pipeline.run(\n",
    "        {\n",
    "            \"retriever\": {\"query\": prompt_Role},\n",
    "            \"prompt_builder\": {\"task\": task, \"process\": process_text},\n",
    "        }\n",
    "    )\n",
    "    processing_time_role = datetime.now() - start_time_role\n",
    "    processing_duration_role = processing_time_role.total_seconds()\n",
    "    input_tokens_Role = response_Roles[\"llm\"][\"meta\"][0][\"prompt_eval_count\"]\n",
    "    output_tokens_Role = response_Roles[\"llm\"][\"meta\"][0][\"eval_count\"]\n",
    "    cleaned_roles = ''.join(response_Roles[\"llm\"][\"replies\"])\n",
    "    cleaned_roles = cleaned_roles.replace(\"'\", '').replace(\"{\", '').replace(\"}\", '').replace(\"[\", '').replace(\"]\", '').replace(\":\", '').replace(\"\\\"roles\\\"\", '').replace(\"\\n\",'').replace(\" \", '').replace(\"\\\",\\\"\",'\\\", \\\"').replace(\"\\\\\",'')\n",
    "\n",
    "    start_time_activity = datetime.now()\n",
    "    response_Activities = activity_pipeline.run(\n",
    "        {\n",
    "            \"retriever_Activity\": {\"query\": prompt_Activity},\n",
    "            \"prompt_builder_Activity\": {\"process\": process_text, \"roles\": cleaned_roles},\n",
    "        }\n",
    "    )\n",
    "    processing_time_activity = datetime.now() - start_time_activity\n",
    "    processing_duration_activity = processing_time_activity.total_seconds()\n",
    "    input_tokens_Activity = response_Activities[\"llm2\"][\"meta\"][0][\"prompt_eval_count\"]\n",
    "    output_tokens_Activity = response_Activities[\"llm2\"][\"meta\"][0][\"eval_count\"]\n",
    "    cleaned_activities = ''.join(response_Activities[\"llm2\"][\"replies\"])\n",
    "    cleaned_activities = cleaned_activities.replace(\"'\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\\"roles\\\"\", '').replace(\"\\n\",'').replace(\"\\\",\\\"\",'\\\", \\\"').replace(\"\\\\\",'').replace('}{\"activity','},{\"activity').replace('} {\"activity','},{\"activity')\n",
    "\n",
    "    start_time_condition = datetime.now()\n",
    "    response_Condition = condition_pipeline.run(\n",
    "        {\n",
    "            \"retriever_condition\": {\"query\": prompt_Condition},\n",
    "            \"prompt_builder_Condition\": {\"process\": process_text, \"activities\": cleaned_activities},\n",
    "        }\n",
    "    )\n",
    "    processing_time_condition = datetime.now() - start_time_condition\n",
    "    processing_duration_condition = processing_time_condition.total_seconds()\n",
    "    input_tokens_condition = response_Condition[\"llm_cond\"][\"meta\"][0][\"prompt_eval_count\"]\n",
    "    output_tokens_condition = response_Condition[\"llm_cond\"][\"meta\"][0][\"eval_count\"]\n",
    "    cleaned_Condition = ''.join(response_Condition[\"llm_cond\"][\"replies\"])\n",
    "    cleaned_Condition = cleaned_Condition.replace(\"'\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\n\",'').replace(\"  \",'').replace(\"\\\",\\\"\",'\\\", \\\"').replace(\"\\\\\",'').replace('}{\"constraint','},{\"constraint').replace('} {\"constraint','},{\"constraint')\n",
    "\n",
    "    start_time_Response = datetime.now()\n",
    "    response_Response = response_pipeline.run(\n",
    "        {\n",
    "            \"retriever_response\": {\"query\": prompt_Response},\n",
    "            \"prompt_builder_response\": {\"process\": process_text, \"activities\": cleaned_activities},\n",
    "        }\n",
    "    )\n",
    "    processing_time_Response = datetime.now() - start_time_Response\n",
    "    processing_duration_response = processing_time_Response.total_seconds()\n",
    "    input_tokens_response = response_Response[\"llm_resp\"][\"meta\"][0][\"prompt_eval_count\"]\n",
    "    output_tokens_response = response_Response[\"llm_resp\"][\"meta\"][0][\"eval_count\"]\n",
    "    cleaned_Response = ''.join(response_Response[\"llm_resp\"][\"replies\"])\n",
    "    cleaned_Response = cleaned_Response.replace(\"'\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\n\",'').replace(\"  \",'').replace(\"\\\",\\\"\",'\\\", \\\"').replace(\"\\\\\",'').replace('}{\"constraint','},{\"constraint').replace('} {\"constraint','},{\"constraint')\n",
    "\n",
    "    start_time_Include = datetime.now()\n",
    "    response_Include = include_pipeline.run(\n",
    "        {\n",
    "            \"retriever_include\": {\"query\": prompt_Include},\n",
    "            \"prompt_builder_include\": {\"process\": process_text, \"activities\": cleaned_activities},\n",
    "        }\n",
    "    )\n",
    "    processing_time_Include = datetime.now() - start_time_Include\n",
    "    processing_duration_include= processing_time_Include.total_seconds()\n",
    "    input_tokens_include= response_Include[\"llm_include\"][\"meta\"][0][\"prompt_eval_count\"]\n",
    "    output_tokens_include= response_Include[\"llm_include\"][\"meta\"][0][\"eval_count\"]\n",
    "    cleaned_Include= ''.join(response_Include[\"llm_include\"][\"replies\"])\n",
    "    cleaned_Include= cleaned_Include.replace(\"'\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\n\",'').replace(\"  \",'').replace(\"\\\",\\\"\",'\\\", \\\"').replace(\"\\\\\",'').replace('}{\"constraint','},{\"constraint').replace('} {\"constraint','},{\"constraint')\n",
    "\n",
    "    start_time_Exclude = datetime.now()\n",
    "    response_Exclude = exclude_pipeline.run(\n",
    "        {\n",
    "            \"retriever_exclude\": {\"query\": prompt_Exclude},\n",
    "            \"prompt_builder_exclude\": {\"process\": process_text, \"activities\": cleaned_activities},\n",
    "        }\n",
    "    )\n",
    "    processing_time_Exclude = datetime.now() - start_time_Exclude\n",
    "    processing_duration_exclude= processing_time_Exclude.total_seconds()\n",
    "    input_tokens_exclude= response_Exclude[\"llm_exclude\"][\"meta\"][0][\"prompt_eval_count\"]\n",
    "    output_tokens_exclude= response_Exclude[\"llm_exclude\"][\"meta\"][0][\"eval_count\"]\n",
    "    cleaned_Exclude= ''.join(response_Exclude[\"llm_exclude\"][\"replies\"])\n",
    "    cleaned_Exclude= cleaned_Exclude.replace(\"'\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\n\",'').replace(\"  \",'').replace(\"\\\",\\\"\",'\\\", \\\"').replace(\"\\\\\",'').replace('}{\"constraint','},{\"constraint').replace('} {\"constraint','},{\"constraint')\n",
    "\n",
    "    start_time_Milestone = datetime.now()\n",
    "    response_Milestone = milestone_pipeline.run(\n",
    "        {\n",
    "            \"retriever_milestone\": {\"query\": prompt_Milestone},\n",
    "            \"prompt_builder_milestone\": {\"process\": process_text, \"activities\": cleaned_activities},\n",
    "        }\n",
    "    )\n",
    "    processing_time_Milestone = datetime.now() - start_time_Milestone\n",
    "    processing_duration_milestone= processing_time_Milestone.total_seconds()\n",
    "    input_tokens_milestone= response_Milestone[\"llm_mile\"][\"meta\"][0][\"prompt_eval_count\"]\n",
    "    output_tokens_milestone= response_Milestone[\"llm_mile\"][\"meta\"][0][\"eval_count\"]\n",
    "    cleaned_Milestone= ''.join(response_Milestone[\"llm_mile\"][\"replies\"])\n",
    "    cleaned_Milestone= cleaned_Milestone.replace(\"'\", '').replace(\"[\", '').replace(\"]\", '').replace(\"\\n\",'').replace(\"  \",'').replace(\"\\\",\\\"\",'\\\", \\\"').replace(\"\\\\\",'').replace('}{\"constraint','},{\"constraint').replace('} {\"constraint','},{\"constraint')\n",
    "\n",
    "    processing_duration_rule = processing_duration_condition + processing_duration_response + processing_duration_include + processing_duration_exclude + processing_duration_milestone\n",
    "    input_tokens_Rule = (input_tokens_condition + input_tokens_response + input_tokens_include + input_tokens_exclude + input_tokens_milestone) / 5\n",
    "    output_tokens_Rule = (output_tokens_condition + output_tokens_response + output_tokens_include + output_tokens_exclude + output_tokens_milestone) / 5\n",
    "    cleaned_rules = cleaned_Condition + \", \" + cleaned_Response + \", \" + cleaned_Include + \", \" + cleaned_Exclude + \", \" + cleaned_Milestone\n",
    "\n",
    "    return cleaned_roles, processing_duration_role, input_tokens_Role, output_tokens_Role, cleaned_activities, processing_duration_activity, input_tokens_Activity, output_tokens_Activity, cleaned_rules, processing_duration_rule, input_tokens_Rule, output_tokens_Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e768dbe",
   "metadata": {},
   "source": [
    "## Create JSON from Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2050135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateJSON(roles,activities,rules):\n",
    "    rolesString = '\"roles\": [' + roles + ']'\n",
    "    activitiesString = '\"activities\": [' + activities + ']'\n",
    "    rulesString = '\"constraints\": [' + rules + ']'\n",
    "    graphString = '{\"DCRgraph\": {' + rolesString + ', ' + activitiesString + ', ' + rulesString + '} }'\n",
    "    \n",
    "    # print(rolesString)\n",
    "    # print(activitiesString)\n",
    "    # print(rulesString)\n",
    "    # print(graphString)\n",
    "\n",
    "    graphJSON = json.loads(graphString)\n",
    "\n",
    "    return graphJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0704d28",
   "metadata": {},
   "source": [
    "## Generate DCR Editor XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5cf5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the code for json_to_xml() was mostly generated using GPT-4o mini\n",
    "def json_to_xml(json_obj):\n",
    "    # Create the root element\n",
    "    definitions = ET.Element(\"dcr:definitions\", {\n",
    "        \"xmlns:dcr\": \"http://tk/schema/dcr\",\n",
    "        \"xmlns:dcrDi\": \"http://tk/schema/dcrDi\",\n",
    "        \"xmlns:dc\": \"http://www.omg.org/spec/DD/20100524/DC\"\n",
    "    })\n",
    "\n",
    "    # Create dcrGraph element\n",
    "    dcr_graph = ET.SubElement(definitions, \"dcr:dcrGraph\", id=\"dcrGraph\")\n",
    "\n",
    "    # Create events\n",
    "    event_ids = {}\n",
    "    for activity in json_obj[\"DCRgraph\"][\"activities\"]:\n",
    "        role = activity[\"role\"]\n",
    "        description = activity[\"activity\"]\n",
    "        event_id = f\"Event_{uuid.uuid4().hex[:8]}\"  # Generate a unique event ID\n",
    "        event_ids[event_id] = activity  # Store the event ID with its activity for later use\n",
    "\n",
    "        event = ET.SubElement(dcr_graph, \"dcr:event\", {\n",
    "            \"id\": event_id,\n",
    "            \"role\": role,\n",
    "            \"description\": description,\n",
    "            \"included\": \"true\",\n",
    "            \"executed\": \"false\",\n",
    "            \"pending\": \"false\",\n",
    "            \"enabled\": \"false\"\n",
    "        })\n",
    "\n",
    "    # Create relations\n",
    "    relation_ids = []\n",
    "    for constraint in json_obj[\"DCRgraph\"][\"constraints\"]:\n",
    "        source_activity = constraint[\"source activity\"]\n",
    "        target_activity = constraint[\"target activity\"]\n",
    "        relation_id = f\"Relation_{uuid.uuid4().hex[:8]}\"  # Generate a unique relation ID\n",
    "\n",
    "        #check whether constraint type matches DCR Editor XML types\n",
    "        if constraint[\"constraint\"] == \"Condition\":\n",
    "            constraint_type = \"condition\"\n",
    "        elif constraint[\"constraint\"] == \"Response\":\n",
    "            constraint_type = \"response\"\n",
    "        elif constraint[\"constraint\"] == \"Exclude\":\n",
    "            constraint_type = \"exclude\"\n",
    "        elif constraint[\"constraint\"] == \"Include\":\n",
    "            constraint_type = \"include\"\n",
    "        elif constraint[\"constraint\"] == \"Milestone\":\n",
    "            constraint_type = \"milestone\"\n",
    "        else:\n",
    "            raise TypeError(\"Constraint Type was not identified correctly\")\n",
    "        \n",
    "        # Find the corresponding event IDs\n",
    "        source_event_id = next((eid for eid, act in event_ids.items() if act[\"activity\"] == source_activity), None)\n",
    "        target_event_id = next((eid for eid, act in event_ids.items() if act[\"activity\"] == target_activity), None)\n",
    "\n",
    "        if source_event_id and target_event_id:\n",
    "            # Create the dcr:relation with a unique ID\n",
    "            ET.SubElement(dcr_graph, \"dcr:relation\", {\n",
    "                \"id\": relation_id,\n",
    "                \"type\": constraint_type, \n",
    "                \"sourceRef\": source_event_id,\n",
    "                \"targetRef\": target_event_id\n",
    "            })\n",
    "            relation_ids.append(relation_id)  # Store the relation ID for later use\n",
    "\n",
    "    # Create dcrRootBoard element\n",
    "    root_board = ET.SubElement(definitions, \"dcrDi:dcrRootBoard\", id=\"RootBoard\")\n",
    "    plane = ET.SubElement(root_board, \"dcrDi:dcrPlane\", id=\"Plane\", boardElement=\"dcrGraph\")\n",
    "\n",
    "    # Create shapes for the diagram\n",
    "    for event_id in event_ids.keys():\n",
    "        shape = ET.SubElement(plane, \"dcrDi:dcrShape\", id=f\"{event_id}_di\", boardElement=event_id)\n",
    "        # Example bounds, you can adjust the coordinates as needed\n",
    "        ET.SubElement(shape, \"dc:Bounds\", x=\"640\", y=\"230\", width=\"130\", height=\"150\")\n",
    "\n",
    "    # Create dcrDi:relation elements with unique IDs\n",
    "    for relation_id in relation_ids:\n",
    "        # Create a corresponding dcrDi:relation\n",
    "        relation_di_id = f\"{relation_id}_di\"  # ID for dcrDi:relation\n",
    "        relation_di = ET.SubElement(plane, \"dcrDi:relation\", id=relation_di_id, boardElement=relation_id)\n",
    "        # Example waypoints, you can adjust the coordinates as needed\n",
    "        ET.SubElement(relation_di, \"dcrDi:waypoint\", x=\"705\", y=\"380\")\n",
    "        ET.SubElement(relation_di, \"dcrDi:waypoint\", x=\"705\", y=\"400\")\n",
    "        ET.SubElement(relation_di, \"dcrDi:waypoint\", x=\"620\", y=\"400\")\n",
    "        ET.SubElement(relation_di, \"dcrDi:waypoint\", x=\"620\", y=\"305\")\n",
    "        ET.SubElement(relation_di, \"dcrDi:waypoint\", x=\"640\", y=\"305\")\n",
    "\n",
    "    # Convert to string\n",
    "    xml_str = ET.tostring(definitions, encoding='UTF-8', xml_declaration=True).decode('UTF-8')\n",
    "    return xml_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4add6",
   "metadata": {},
   "source": [
    "## Combined Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bb085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 19\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 18\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 17\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 16\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 15\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 14\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 13\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 12\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 11\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 10\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 9\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 8\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 7\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 6\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 5\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 4\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 3\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 2\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 1\n",
      "\n",
      "\n",
      "Graph Generation failed with error (,Pipeline_C1_)\n",
      "1 validation error for GenerateRequest\n",
      "model\n",
      "  String should have at least 1 character [type=string_too_short, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/string_too_short\n",
      "Iterations left: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exceeded maximumg number of runs. Generation of Graph failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m current_run >= loop_limit:\n\u001b[32m     17\u001b[39m         \u001b[38;5;66;03m# safety mechanism to ensure termination if an unexpected issue is not handled\u001b[39;00m\n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# important to leave in when running everything automatically\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExceeded maximumg number of runs. Generation of Graph failed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     21\u001b[39m         roles, role_time, role_input, role_output, activities, activity_time, activity_input, activity_output, rules, rule_time, rule_input, rule_output = runPromptPipeline()\n",
      "\u001b[31mValueError\u001b[39m: Exceeded maximumg number of runs. Generation of Graph failed."
     ]
    }
   ],
   "source": [
    "current_run = 0\n",
    "generation_start_time = datetime.now()\n",
    "errors = 0\n",
    "role_times = []\n",
    "role_input_token = []\n",
    "role_output_token = []\n",
    "activity_times = []\n",
    "activity_input_token = []\n",
    "activity_output_token = []\n",
    "rule_times = []\n",
    "rule_input_token = []\n",
    "rule_output_token = []\n",
    "\n",
    "while True:\n",
    "    if current_run >= loop_limit:\n",
    "        # safety mechanism to ensure termination if an unexpected issue is not handled\n",
    "        # important to leave in when running everything automatically\n",
    "        raise ValueError(\"Exceeded maximumg number of runs. Generation of Graph failed.\")\n",
    "    try:\n",
    "        roles, role_time, role_input, role_output, activities, activity_time, activity_input, activity_output, rules, rule_time, rule_input, rule_output = runPromptPipeline()\n",
    "        role_times.append(role_time)\n",
    "        role_input_token.append(role_input)\n",
    "        role_output_token.append(role_output)\n",
    "        activity_times.append(activity_time)\n",
    "        activity_input_token.append(activity_input)\n",
    "        activity_output_token.append(activity_output)\n",
    "        rule_times.append(rule_time)\n",
    "        rule_input_token.append(rule_input)\n",
    "        rule_output_token.append(rule_output)\n",
    "        graphJSON = generateJSON(roles,activities,rules)\n",
    "        print(\"Parsing to JSON successful\")\n",
    "        xml = json_to_xml(graphJSON)\n",
    "        print(f\"XML Generation successful ({process_name},Pipeline_A2_{prompt_name})\")\n",
    "        print(\"xml:\", xml)\n",
    "        print(\"\\n\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        current_run += 1\n",
    "        errors += 1\n",
    "        print(f\"Graph Generation failed with error ({process_name},Pipeline_A2_{prompt_name})\")\n",
    "        print(e, flush=True)\n",
    "        runs_left = loop_limit - current_run\n",
    "        print(\"Iterations left: \" + str(runs_left))\n",
    "        print(\"\\n\")\n",
    "\n",
    "generation_finished_time = datetime.now() - generation_start_time\n",
    "generation_duration = generation_finished_time.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716363d2",
   "metadata": {},
   "source": [
    "## Save Time to Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_times = f\"{process_name};{generation_duration};{role_times};{role_input_token};{role_output_token};{activity_times};{activity_input_token};{activity_output_token};{rule_times};{rule_input_token};{rule_output_token};{errors}\\n\"\n",
    "\n",
    "folder = Path('./6_Time_Analysis') / \"data\" / large_language_model / \"Pipeline_A2\"\n",
    "folder.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "file_name = f\"{prompt_name}.txt\"\n",
    "file_path = folder / file_name \n",
    "\n",
    "with open(file_path, 'a+') as file:\n",
    "    file.write(new_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aee1a",
   "metadata": {},
   "source": [
    "## Save XML to Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940312a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(result_xml_path) / large_language_model / \"Pipeline_A2\" / prompt_name\n",
    "folder.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "file_name = f\"{process_name}_{large_language_model}_{prompt_name}_{datetime.now().date()}_{datetime.now().time()}.xml\"\n",
    "file_path = folder / file_name \n",
    "\n",
    "with open(file_path, 'w') as result_destination:\n",
    "    result_destination.write(xml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DICE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
